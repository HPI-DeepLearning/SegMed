{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Cropping2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta, Nadam\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "WIDTH, HEIGHT = 240, 240\n",
    "SOURCE_FILE = os.path.join('..', 'data', 'week3', 'week3_just_tumor_{}.csv')\n",
    "SOURCE_FILES = [SOURCE_FILE.format(i) for i in range(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = list(range(WIDTH * HEIGHT)) + ['label']\n",
    "# index = list(range(999 * 10))\n",
    "chunks = []\n",
    "for i, file_ in enumerate(SOURCE_FILES[:4] + SOURCE_FILES[-4:]):\n",
    "    print('Processing chunk file #{}'.format(i))\n",
    "    # chunksize=100 -> returns TextFileReader for iteration\n",
    "    print('from', i*999, 'to', i*999 + 998)\n",
    "    chunk_df = pd.read_csv(file_, dtype=np.uint8, nrows=999)\n",
    "    chunks.append(chunk_df)\n",
    "df = pd.concat(chunks).dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    # Pop labels and transform them to vectors\n",
    "    y = dataset.pop('label')\n",
    "    y = y.values.reshape((-1, 1))\n",
    "    # Reshape the features for CNN\n",
    "    # X = dataset.as_matrix().reshape(dataset.shape[0], 1, WIDTH, HEIGHT).astype(np.float32)\n",
    "    X = dataset.as_matrix().reshape(dataset.shape[0], 1, WIDTH, HEIGHT).astype(np.float32)\n",
    "    # Norm datax\n",
    "    X /= 255\n",
    "    # Convert labels to categorical values\n",
    "    y = keras.utils.to_categorical(y, 2)\n",
    "    return X, y\n",
    "\n",
    "def get_shuffled_splitted_data():\n",
    "    # Shuffle and split data into: 70% train, 20% test, 10% validation\n",
    "    train, test, val = np.split(data.sample(frac=1), [int(.7*len(data)), int(.85*len(data))])    \n",
    "    # Extract labels, normalize, preprocess for keras\n",
    "    X_train, y_train = preprocess_dataset(train)\n",
    "    X_test, y_test = preprocess_dataset(test)\n",
    "    X_val, y_val = preprocess_dataset(val)\n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val\n",
    "\n",
    "# Collect new dataset containing sagittal images including scull and tumor\n",
    "data = df\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = get_shuffled_splitted_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', input_shape=(1, WIDTH, HEIGHT)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=Nadam(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def setup_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(7, 7), input_shape=(1, WIDTH, HEIGHT)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, kernel_size=(5, 5), input_shape=(1, WIDTH, HEIGHT)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(7, 7)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=Nadam(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    K.set_image_dim_ordering('th')\n",
    "    batch_size = 36\n",
    "    num_classes = 2\n",
    "    epochs = 10\n",
    "    # For storing the validation loss values\n",
    "    history = keras.callbacks.History()\n",
    "    # Train model\n",
    "    model = setup_simple_model()\n",
    "    model_results = model.fit(X_train, y_train,\n",
    "                              batch_size=batch_size,\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              validation_data=(X_test, y_test),\n",
    "                              callbacks=[history])\n",
    "    # Evaluate model on validation set\n",
    "    print('\\nValidate model on {} unknown validation samples:'.format(X_val.shape[0]))\n",
    "    val_score = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print('Val loss:', val_score[0])\n",
    "    print('Val accuracy:', val_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store output in output.py\n",
    "%save -a output _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'Hi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot validation loss\n",
    "utils.plot_history(model_results)\n",
    "plt.savefig('model_history.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Always same results\n",
    "np.random.seed(1)\n",
    "y_val_pred = model.predict(X_val, batch_size=32, verbose=0)\n",
    "y_val_pred = np.round(y_val_pred).astype(int)\n",
    "is_lgg = y_val.argmax(axis=1) == 0\n",
    "utils.plot_predicted_samples(4, X_val[is_lgg], y_val[is_lgg], y_val_pred[is_lgg], 'Validation set - LGG', (WIDTH, HEIGHT))\n",
    "utils.plot_predicted_samples(4, X_val[is_lgg == False], y_val[is_lgg == False], y_val_pred[is_lgg == False], 'Validation set - HGG', (WIDTH, HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Always same results (grayscale)\n",
    "np.random.seed(1)\n",
    "utils.plot_predicted_samples(4, X_val[is_lgg], y_val[is_lgg], y_val_pred[is_lgg], 'Validation set - LGG', (WIDTH, HEIGHT))\n",
    "utils.plot_predicted_samples(4, X_val[is_lgg == False], y_val[is_lgg == False], y_val_pred[is_lgg == False], 'Validation set - HGG', (WIDTH, HEIGHT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Our network converges unexpectedly quickly. This might be due to the following problems:\n",
    "- The tumor images are resized and are somewhat blurred\n",
    "- For some tumor images you can easily see that it has been created by two seperate pictures\n",
    "- The healthy images contain sometimes a very different shape (e.g. above #108)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reload utils model if you changed a function\n",
    "# import imp\n",
    "# imp.reload(utils)\n",
    "utils.plot_model(model, 'skull_classification_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
