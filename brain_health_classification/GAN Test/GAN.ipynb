{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import utils\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Cropping2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta, Nadam\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "WIDTH, HEIGHT = 124, 124\n",
    "SOURCE_FILE = os.path.join('..', 'data', 'scull_set.txt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    # Pop labels and transform them to vectors\n",
    "    y = dataset.pop('label')\n",
    "    y = y.values.reshape((-1, 1))\n",
    "    # Reshape the features for CNN\n",
    "    X = dataset.as_matrix().reshape(dataset.shape[0], 1, WIDTH, HEIGHT).astype(np.float32)\n",
    "    # Norm data\n",
    "    X /= 255\n",
    "    # Convert labels to categorical values\n",
    "    y = keras.utils.to_categorical(y, 2)\n",
    "    return X, y\n",
    "\n",
    "def get_shuffled_splitted_data(path=SOURCE_FILE):\n",
    "    df = pd.read_csv(path)\n",
    "    # Shuffle and split data into: 70% train, 20% test, 10% validation\n",
    "    train, test, val = np.split(df.sample(frac=1), [int(.7*len(df)), int(.9*len(df))])    \n",
    "    # Extract labels, normalize, preprocess for keras\n",
    "    X_train, y_train = preprocess_dataset(train)\n",
    "    X_test, y_test = preprocess_dataset(test)\n",
    "    X_val, y_val = preprocess_dataset(val)\n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val\n",
    "\n",
    "# Collect new dataset containing sagittal images including scull and tumor\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = get_shuffled_splitted_data()\n",
    "WIDTH, HEIGHT = 124, 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "\n",
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((128, 7, 7), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(\n",
    "                        64, 5, 5,\n",
    "                        border_mode='same',\n",
    "                        dim_ordering=\"th\",\n",
    "                        input_shape=(1, WIDTH, HEIGHT)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(128, 5, 5))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "\n",
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image\n",
    "\n",
    "\n",
    "def train(X_train, BATCH_SIZE):\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    discriminator_on_generator.compile(\n",
    "        loss='binary_crossentropy', optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, 100))\n",
    "    for epoch in range(100):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "            if index % 20 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                Image.fromarray(image.astype(np.uint8)).save(\n",
    "                    str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "                noise, [1] * BATCH_SIZE)\n",
    "            discriminator.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights('generator', True)\n",
    "                discriminator.save_weights('discriminator', True)\n",
    "\n",
    "\n",
    "def generate(BATCH_SIZE, nice=False):\n",
    "    generator = generator_model()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    generator.load_weights('generator')\n",
    "    if nice:\n",
    "        discriminator = discriminator_model()\n",
    "        discriminator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        discriminator.load_weights('discriminator')\n",
    "        noise = np.zeros((BATCH_SIZE*20, 100))\n",
    "        for i in range(BATCH_SIZE*20):\n",
    "            noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "        generated_images = generator.predict(noise, verbose=1)\n",
    "        d_pret = discriminator.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE, 1) +\n",
    "                               (generated_images.shape[2:]), dtype=np.float32)\n",
    "        for i in range(int(BATCH_SIZE)):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, 0, :, :] = generated_images[idx, 0, :, :]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.zeros((BATCH_SIZE, 100))\n",
    "        for i in range(BATCH_SIZE):\n",
    "            noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "        generated_images = generator.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        \"generated_image.png\")\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", type=str)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--nice\", dest=\"nice\", action=\"store_true\")\n",
    "    parser.set_defaults(nice=False)\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), input_shape=(1, 124, 1..., data_format=\"channels_first\", padding=\"same\")`\n",
      "/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5))`\n",
      "/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
      "/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (5, 5), padding=\"same\")`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "number of input channels does not match corresponding dimension of filter, 512 != 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-405ca30f8829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-9bb8aef65d33>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_train, BATCH_SIZE)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mdiscriminator_on_generator\u001b[0m \u001b[0;34m=\u001b[0m         \u001b[0mgenerator_containing_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0md_optim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mg_optim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-9bb8aef65d33>\u001b[0m in \u001b[0;36mgenerator_containing_discriminator\u001b[0;34m(generator, discriminator)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    464\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2027\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2028\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2176\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2179\u001b[0m                             output_masks = _to_list(layer.compute_mask(computed_tensor,\n\u001b[1;32m   2180\u001b[0m                                                                        computed_mask))\n",
      "\u001b[0;32m/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[0;32m/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3093\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3094\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3095\u001b[0;31m         data_format='NHWC')\n\u001b[0m\u001b[1;32m   3096\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_postprocess_conv2d_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    639\u001b[0m           \u001b[0;34m\"number of input channels does not match corresponding dimension of filter, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m           \"{} != {}\".format(input_channels_dim, filter.get_shape()[\n\u001b[0;32m--> 641\u001b[0;31m               num_spatial_dims]))\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     strides, dilation_rate = _get_strides_and_dilation_rate(\n",
      "\u001b[0;31mValueError\u001b[0m: number of input channels does not match corresponding dimension of filter, 512 != 1"
     ]
    }
   ],
   "source": [
    "train(X_train, BATCH_SIZE=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
      "/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (5, 5), padding=\"same\")`\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "`load_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-030cf63104f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-9bb8aef65d33>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(BATCH_SIZE, nice)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SGD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `load_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "generate(BATCH_SIZE=32, nice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "DCGAN on MNIST using Keras\n",
    "Author: Rowel Atienza\n",
    "Project: https://github.com/roatienza/Deep-Learning-Experiments\n",
    "Dependencies: tensorflow 1.0 and keras 2.0\n",
    "Usage: python3 dcgan_mnist.py\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n",
    "\n",
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=124, img_cols=124, channel=1):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.D = None   # discriminator\n",
    "        self.G = None   # generator\n",
    "        self.AM = None  # adversarial model\n",
    "        self.DM = None  # discriminator model\n",
    "\n",
    "    # (W−F+2P)/S+1\n",
    "    def discriminator(self):\n",
    "        if self.D:\n",
    "            return self.D\n",
    "        self.D = Sequential()\n",
    "        depth = 64\n",
    "        dropout = 0.4\n",
    "        # In: 28 x 28 x 1, depth = 1\n",
    "        # Out: 10 x 10 x 1, depth=64\n",
    "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n",
    "            padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same',\\\n",
    "                activation=LeakyReLU(alpha=0.2)))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same',\\\n",
    "                activation=LeakyReLU(alpha=0.2)))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same',\\\n",
    "                activation=LeakyReLU(alpha=0.2)))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        # Out: 1-dim probability\n",
    "        self.D.add(Flatten())\n",
    "        self.D.add(Dense(1))\n",
    "        self.D.add(Activation('sigmoid'))\n",
    "        self.D.summary()\n",
    "        return self.D\n",
    "\n",
    "    def generator(self):\n",
    "        if self.G:\n",
    "            return self.G\n",
    "        self.G = Sequential()\n",
    "        dropout = 0.4\n",
    "        depth = 64+64+64+64\n",
    "        dim = 31 \n",
    "        # In: 100\n",
    "        # Out: dim x dim x depth\n",
    "        self.G.add(Dense(dim*dim*depth, input_dim=100))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(Reshape((dim, dim, depth)))\n",
    "        self.G.add(Dropout(dropout))\n",
    "\n",
    "        # In: dim x dim x depth\n",
    "        # Out: 2*dim x 2*dim x depth/2\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n",
    "        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "        self.G.add(Activation('sigmoid'))\n",
    "        self.G.summary()\n",
    "        return self.G\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        optimizer = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator())\n",
    "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.DM\n",
    "\n",
    "    def adversarial_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        optimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.generator())\n",
    "        self.AM.add(self.discriminator())\n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.AM\n",
    "\n",
    "class MNIST_DCGAN(object):\n",
    "    def __init__(self, X_train):\n",
    "        self.img_rows = 124\n",
    "        self.img_cols = 124\n",
    "        self.channel = 1\n",
    "\n",
    "        self.x_train = X_train\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator =  self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "    \n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "        for i in range(train_steps):\n",
    "            images_train = self.x_train[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            images_fake = self.generator.predict(noise)\n",
    "            x = np.concatenate((images_train, images_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(i+1))\n",
    "\n",
    "    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n",
    "        filename = 'mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "            images = self.generator.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/naruto/Seminar-Med-Seg2017/SegMed/segmed/lib/python3.5/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 62, 62, 64)        1664      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 31, 31, 128)       204928    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 131073    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,434,433\n",
      "Trainable params: 4,434,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 246016)            24847616  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 246016)            984064    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 246016)            0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 62, 62, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 62, 62, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 62, 62, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 124, 124, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 124, 124, 64)      204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 124, 124, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 124, 124, 32)      51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 124, 124, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 124, 124, 1)       801       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 124, 124, 1)       0         \n",
      "=================================================================\n",
      "Total params: 26,908,801\n",
      "Trainable params: 26,416,321\n",
      "Non-trainable params: 492,480\n",
      "_________________________________________________________________\n",
      "0: [D loss: 0.694286, acc: 0.500000]  [A loss: 16.118095, acc: 0.000000]\n",
      "1: [D loss: 5.483119, acc: 0.500000]  [A loss: 16.118095, acc: 0.000000]\n",
      "2: [D loss: 7.544379, acc: 0.500000]  [A loss: 0.000064, acc: 1.000000]\n",
      "3: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "4: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "5: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "6: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "7: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "8: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "9: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "10: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "11: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "12: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "13: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "14: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "15: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "16: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "17: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "18: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "19: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "20: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "21: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "22: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "23: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "24: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "25: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "26: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "27: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "28: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "29: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "30: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "31: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "32: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "33: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "34: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "35: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "36: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "37: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "38: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "39: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "40: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "41: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "42: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "43: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "44: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "45: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "46: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "47: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "48: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "49: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "50: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "52: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "53: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "54: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "55: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "56: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "57: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "58: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "59: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "60: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "61: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "62: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "63: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "64: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "65: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "66: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "67: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "68: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "69: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "70: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "71: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "72: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "73: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "74: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "75: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "76: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "77: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "78: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "79: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "80: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "81: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "82: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "83: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "84: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "85: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "86: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "87: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "88: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "89: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "90: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "91: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "92: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "93: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "94: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "95: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "96: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "97: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "98: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "99: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "100: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "101: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "102: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "103: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "104: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "105: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "106: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "107: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "108: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "109: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "110: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "111: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "112: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "113: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "114: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "115: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "116: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "117: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "118: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "119: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "120: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "121: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "122: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "123: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "124: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "125: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "126: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "127: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "128: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "129: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "130: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "131: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "132: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "133: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "134: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "135: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "136: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "137: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "138: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "139: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "140: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "141: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "142: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "143: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "144: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "145: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "146: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "147: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "148: [D loss: 7.971193, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n"
     ]
    }
   ],
   "source": [
    "swapped_train = np.swapaxes(X_train, 1, 3)\n",
    "swapped_train = np.swapaxes(swapped_train, 1, 2)\n",
    "mnist_dcgan = MNIST_DCGAN(swapped_train)\n",
    "timer = ElapsedTimer()\n",
    "mnist_dcgan.train(train_steps=1000, batch_size=10, save_interval=500)\n",
    "timer.elapsed_time()\n",
    "mnist_dcgan.plot_images(fake=True)\n",
    "mnist_dcgan.plot_images(fake=False, save2file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dcgan.plot_images(fake=True)\n",
    "mnist_dcgan.plot_images(fake=False, save2file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
