{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Cropping2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta, Nadam\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "WIDTH, HEIGHT = 124, 124\n",
    "SOURCE_FILE = os.path.join('..', 'data', 'scull_set.txt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    # Pop labels and transform them to vectors\n",
    "    y = dataset.pop('label')\n",
    "    y = y.values.reshape((-1, 1))\n",
    "    # Reshape the features for CNN\n",
    "    X = dataset.as_matrix().reshape(dataset.shape[0], 1, WIDTH, HEIGHT).astype(np.float32)\n",
    "    # Norm data\n",
    "    X /= 255\n",
    "    # Convert labels to categorical values\n",
    "    y = keras.utils.to_categorical(y, 2)\n",
    "    return X, y\n",
    "\n",
    "def get_shuffled_splitted_data(path=SOURCE_FILE):\n",
    "    df = pd.read_csv(path)\n",
    "    # Shuffle and split data into: 70% train, 20% test, 10% validation\n",
    "    train, test, val = np.split(df.sample(frac=1), [int(.7*len(df)), int(.9*len(df))])    \n",
    "    # Extract labels, normalize, preprocess for keras\n",
    "    X_train, y_train = preprocess_dataset(train)\n",
    "    X_test, y_test = preprocess_dataset(test)\n",
    "    X_val, y_val = preprocess_dataset(val)\n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val\n",
    "\n",
    "# Collect new dataset containing sagittal images including scull and tumor\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = get_shuffled_splitted_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3098 samples, validate on 885 samples\n",
      "Epoch 1/10\n",
      "3098/3098 [==============================] - 1s - loss: 0.6511 - acc: 0.5904 - val_loss: 0.5740 - val_acc: 0.8520\n",
      "Epoch 2/10\n",
      "3098/3098 [==============================] - 1s - loss: 0.4476 - acc: 0.9187 - val_loss: 0.2871 - val_acc: 0.9412\n",
      "Epoch 3/10\n",
      "3098/3098 [==============================] - 1s - loss: 0.2335 - acc: 0.9377 - val_loss: 0.1815 - val_acc: 0.9390\n",
      "Epoch 4/10\n",
      "3098/3098 [==============================] - 1s - loss: 0.1751 - acc: 0.9422 - val_loss: 0.1430 - val_acc: 0.9401\n",
      "Epoch 5/10\n",
      "3098/3098 [==============================] - 1s - loss: 0.1561 - acc: 0.9461 - val_loss: 0.1316 - val_acc: 0.9435\n",
      "Epoch 6/10\n",
      "3098/3098 [==============================] - 1s - loss: 0.1449 - acc: 0.9484 - val_loss: 0.1149 - val_acc: 0.9605\n",
      "Epoch 7/10\n",
      "3098/3098 [==============================] - 1s - loss: 0.1368 - acc: 0.9526 - val_loss: 0.1076 - val_acc: 0.9605\n",
      "Epoch 8/10\n",
      "3098/3098 [==============================] - 1s - loss: 0.1302 - acc: 0.9545 - val_loss: 0.1062 - val_acc: 0.9593\n",
      "Epoch 9/10\n",
      "3098/3098 [==============================] - 1s - loss: 0.1248 - acc: 0.9558 - val_loss: 0.0952 - val_acc: 0.9627\n",
      "Epoch 10/10\n",
      "3098/3098 [==============================] - 1s - loss: 0.1225 - acc: 0.9555 - val_loss: 0.0906 - val_acc: 0.9650\n",
      "\n",
      "Validate model on 443 unknown validation samples:\n",
      "Val loss: 0.0835326319354\n",
      "Val accuracy: 0.972911963883\n"
     ]
    }
   ],
   "source": [
    "def setup_model():\n",
    "    model = Sequential()\n",
    "    model.add(MaxPooling2D(pool_size=(20, 5), input_shape=(1, 124, 124)))\n",
    "    model.add(Conv2D(16, kernel_size=(1, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2))\n",
    "    model.add(Dense(6))\n",
    "    \n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    K.set_image_dim_ordering('th')\n",
    "    batch_size = 32\n",
    "    num_classes = 2\n",
    "    epochs = 10\n",
    "    # For storing the validation loss values\n",
    "    history = keras.callbacks.History()\n",
    "    # Train model\n",
    "    model = setup_model()\n",
    "    model_results = model.fit(X_train, y_train,\n",
    "                              batch_size=batch_size,\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              validation_data=(X_test, y_test),\n",
    "                              callbacks=[history])\n",
    "    # Evaluate model on validation set\n",
    "    print('\\nValidate model on {} unknown validation samples:'.format(X_val.shape[0]))\n",
    "    val_score = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print('Val loss:', val_score[0])\n",
    "    print('Val accuracy:', val_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation loss\n",
    "utils.plot_history(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always same results\n",
    "np.random.seed(1)\n",
    "y_val_pred = model.predict(X_val, batch_size=32, verbose=0)\n",
    "y_val_pred = np.round(y_val_pred).astype(int)\n",
    "no_tumors = y_val.argmax(axis=1) == 0\n",
    "utils.plot_predicted_samples(4, X_val[no_tumors], y_val[no_tumors], y_val_pred[no_tumors], 'Validation set - No Tumor')\n",
    "utils.plot_predicted_samples(4, X_val[no_tumors == False], y_val[no_tumors == False], y_val_pred[no_tumors == False], 'Validation set - Tumor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Our network converges unexpectedly quickly. This might be due to the following problems:\n",
    "- The tumor images are resized and are somewhat blurred\n",
    "- For some tumor images you can easily see that it has been created by two seperate pictures\n",
    "- The healthy images contain sometimes a very different shape (e.g. above #108)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload utils model if you changed a function\n",
    "# import imp\n",
    "# imp.reload(utils)\n",
    "utils.plot_model(model, 'skull_classification_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
