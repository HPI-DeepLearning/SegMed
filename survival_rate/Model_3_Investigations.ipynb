{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Concatenate\n",
    "from keras.layers import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.optimizers import Adadelta, Nadam, Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 120, 120\n",
    "AGE_CLASSES = 100\n",
    "MAX_SURVIVAL = 2000\n",
    "CLASSIFICATION = False\n",
    "SURVIVAL_GROUPS = 4\n",
    "MAX_SLICES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/survival_data.csv\")\n",
    "df.head()\n",
    "orig_X = np.load('data/tumors_small_nz.npy')\n",
    "orig_X = orig_X.transpose((0, 2, 1, 3, 4))\n",
    "X = orig_X\n",
    "\n",
    "if CLASSIFICATION:\n",
    "    Y = utils.as_classes(df['Survival'], SURVIVAL_GROUPS)\n",
    "else:\n",
    "    Y = df['Survival']\n",
    "df['TumorSum'] = X[:, :3].sum(axis=(1, 2, 3, 4))\n",
    "df['TumorSum1'] = X[:, 0:1].sum(axis=(1, 2, 3, 4))\n",
    "df['TumorSum2'] = X[:, 1:2].sum(axis=(1, 2, 3, 4))\n",
    "df['TumorSum3'] = X[:, 2:3].sum(axis=(1, 2, 3, 4))\n",
    "df['BrainSum'] = X[:, 3:].sum(axis=(1, 2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_slices_range(patient, min_=1000):\n",
    "    pixels = patient[0].sum(axis=(1, 2))\n",
    "    start = next(i for i, val in enumerate(pixels) if val >= min_)\n",
    "    end = next(i for i, val in reversed(list(enumerate(pixels))) if val >= min_)\n",
    "    return start, end\n",
    "\n",
    "slices_ranges = [get_slices_range(patient) for patient in orig_X]\n",
    "min_range = min((end - start for start, end in slices_ranges))\n",
    "max_range = max((end - start for start, end in slices_ranges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select `min_range` slices for each patient (middle of tumor slices)\n",
    "downsampled_ix = ((end + start)//2 for start, end in slices_ranges)\n",
    "downsampled_ix = ((middle - min_range//2, middle + min_range//2) for middle in downsampled_ix)\n",
    "downsampled = np.array([orig_X[i, :, start:end] for (i, (start, end)) in enumerate(downsampled_ix)])\n",
    "X = downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat tumor until `max_range` reached\n",
    "upsampled = []\n",
    "for i, (start, end) in enumerate(slices_ranges):\n",
    "    sampling = []\n",
    "    j = 0\n",
    "    while j < max_range:\n",
    "        for k in range(start, end+1):\n",
    "            if j < max_range:\n",
    "                sampling.append(orig_X[i, :, k:k+1])\n",
    "                j += 1\n",
    "    upsampled.append(np.concatenate(sampling, axis=1))\n",
    "upsampled = np.array(upsampled)\n",
    "X = upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tumor 2D\n",
    "\n",
    "One pixel contains the sum of slices containing tumor at this position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tumor2D = orig_X[:, :, :, :, :].sum(axis=2)\n",
    "X = tumor2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example how this will look in the end, the values are between 0 and 16000\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(orig_X[10, i, :, :, :].sum(axis=0))\n",
    "    ax.set_title('Patient 10, Tumor region {}'.format(i))\n",
    "axes[-1].set_title('Patient 10, Brain modality #1')\n",
    "fig.savefig('analysis/tumor_2d.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_splitted_data(X, ages, labels):\n",
    "    assert len(X) == len(labels) == len(ages)\n",
    "    # OneHotEncoding for ages\n",
    "    enc_table = np.eye(AGE_CLASSES)\n",
    "    ages_ohe = np.array([enc_table[int(round(x))] for x in ages])\n",
    "    if not CLASSIFICATION:\n",
    "        # Normalize labels\n",
    "        labels /= MAX_SURVIVAL\n",
    "    # Split data into: 70% train, 15% test, 15% validation\n",
    "    # cuts = [int(.70*len(X)), int(.85*len(X))]\n",
    "    # Use all data for training and testing:\n",
    "    cuts = [int(.9*len(X)), int(1*len(X))]\n",
    "    X1_train, X1_test, X1_val = np.split(X, cuts)\n",
    "    X2_train, X2_test, X2_val = np.split(ages_ohe, cuts)\n",
    "    Y_train, Y_test, Y_val = np.split(labels, cuts)\n",
    "    return X1_train, X2_train, Y_train, X1_test, X2_test, Y_test, X1_val, X2_val, Y_val\n",
    "\n",
    "X1_train, X2_train, Y_train, X1_test, X2_test, Y_test, X1_val, X2_val, Y_val = get_splitted_data(\n",
    "    X, df['Age'], Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp.reload(utils)\n",
    "utils.plot_tumor_position(X)\n",
    "utils.plot_pixels_vs_survival(**locals())\n",
    "utils.plot_age_vs_survival(**locals())\n",
    "utils.plot_corr(df, 10)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO:\n",
    "1. Increase Learning rate\n",
    "2. Increase Drop out\n",
    "3. Only use tumor image slices\n",
    "    a. Upsampling -> sample small tumors\n",
    "    b. Downsampling -> select amount of slices so that it gets only tumor images for each patient\n",
    "4. Only use one tumor slice\n",
    "5. One tumor image containing the number of tumor pixels overall slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred*MAX_SURVIVAL - y_true*MAX_SURVIVAL), axis=-1)\n",
    "\n",
    "def build_model():\n",
    "    main_input = Input(shape=X1_test.shape[1:], dtype='float32', name='main_input')\n",
    "    if len(X.shape) == 5:\n",
    "        x = Conv3D(8, (5, 5, 5), padding='same', activation='relu', data_format='channels_first')(main_input)\n",
    "        x = MaxPooling3D(pool_size=(4, 4, 4))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Conv3D(8, (3, 3, 3), padding='same', activation='relu', data_format='channels_first')(x)\n",
    "        x = MaxPooling3D(pool_size=(4, 4, 4))(x)\n",
    "        x = Dropout(0.15)(x)\n",
    "    else:\n",
    "        x = Conv2D(32, (5, 5), padding='same', data_format='channels_first')(main_input)\n",
    "        x = MaxPooling2D(pool_size=(4, 4))(x)\n",
    "        x = Activation(LeakyReLU())(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Conv2D(64, (3, 3), padding='same', data_format='channels_first')(x)\n",
    "        x = MaxPooling2D(pool_size=(4, 4))(x)\n",
    "        x = Activation(PReLU())(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(128, activation='tanh')(x)\n",
    "    cnn_out = Flatten()(x)\n",
    "    x = Dense(64, activation='sigmoid')(x)\n",
    "    auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(cnn_out)\n",
    "\n",
    "    auxiliary_input = Input(shape=(AGE_CLASSES,), name='aux_input', dtype='float32')\n",
    "    x = Dense(AGE_CLASSES//2, activation='tanh')(auxiliary_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = keras.layers.concatenate([cnn_out, x])\n",
    "    x = Dense(128, activation='tanh')(x)\n",
    "    x = Dense(128, activation='sigmoid')(x)\n",
    "    main_output = Dense(1, dtype='float32', activation='sigmoid', name='main_output')(x)\n",
    "    model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, metrics=[mse],\n",
    "                  loss={'main_output': 'mean_squared_error', 'aux_output': 'mean_squared_error'},\n",
    "                  loss_weights={'main_output': 1, 'aux_output': 0})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146 samples, validate on 17 samples\n",
      "Epoch 1/20\n",
      "146/146 [==============================] - 12s - loss: 0.0602 - main_output_loss: 0.0602 - aux_output_loss: 0.0766 - main_output_mse: 240787.4293 - aux_output_mse: 306501.0771 - val_loss: 0.0518 - val_main_output_loss: 0.0518 - val_aux_output_loss: 0.0293 - val_main_output_mse: 207347.7812 - val_aux_output_mse: 117355.3125\n",
      "Epoch 2/20\n",
      "146/146 [==============================] - 4s - loss: 0.0362 - main_output_loss: 0.0362 - aux_output_loss: 0.0833 - main_output_mse: 144908.6993 - aux_output_mse: 333120.2256 - val_loss: 0.0205 - val_main_output_loss: 0.0205 - val_aux_output_loss: 0.0333 - val_main_output_mse: 81965.3750 - val_aux_output_mse: 133350.4062\n",
      "Epoch 3/20\n",
      "146/146 [==============================] - 4s - loss: 0.0377 - main_output_loss: 0.0377 - aux_output_loss: 0.0761 - main_output_mse: 150741.6351 - aux_output_mse: 304529.1391 - val_loss: 0.0239 - val_main_output_loss: 0.0239 - val_aux_output_loss: 0.0412 - val_main_output_mse: 95484.3281 - val_aux_output_mse: 164929.8750\n",
      "Epoch 4/20\n",
      "146/146 [==============================] - 4s - loss: 0.0323 - main_output_loss: 0.0323 - aux_output_loss: 0.0707 - main_output_mse: 129232.5899 - aux_output_mse: 282716.1494 - val_loss: 0.0408 - val_main_output_loss: 0.0408 - val_aux_output_loss: 0.0380 - val_main_output_mse: 163330.1250 - val_aux_output_mse: 151891.5781\n",
      "Epoch 5/20\n",
      "146/146 [==============================] - 4s - loss: 0.0363 - main_output_loss: 0.0363 - aux_output_loss: 0.0865 - main_output_mse: 145217.2748 - aux_output_mse: 345822.0771 - val_loss: 0.0338 - val_main_output_loss: 0.0338 - val_aux_output_loss: 0.0360 - val_main_output_mse: 135315.9688 - val_aux_output_mse: 144131.0312\n",
      "Epoch 6/20\n",
      "146/146 [==============================] - 4s - loss: 0.0327 - main_output_loss: 0.0327 - aux_output_loss: 0.0873 - main_output_mse: 130601.6531 - aux_output_mse: 349213.6190 - val_loss: 0.0219 - val_main_output_loss: 0.0219 - val_aux_output_loss: 0.0350 - val_main_output_mse: 87468.1250 - val_aux_output_mse: 139838.3438\n",
      "Epoch 7/20\n",
      "146/146 [==============================] - 4s - loss: 0.0323 - main_output_loss: 0.0323 - aux_output_loss: 0.0907 - main_output_mse: 129202.4780 - aux_output_mse: 362698.5300 - val_loss: 0.0236 - val_main_output_loss: 0.0236 - val_aux_output_loss: 0.0357 - val_main_output_mse: 94304.5547 - val_aux_output_mse: 142924.1875\n",
      "Epoch 8/20\n",
      "146/146 [==============================] - 4s - loss: 0.0311 - main_output_loss: 0.0311 - aux_output_loss: 0.0867 - main_output_mse: 124350.4213 - aux_output_mse: 346736.3750 - val_loss: 0.0284 - val_main_output_loss: 0.0284 - val_aux_output_loss: 0.0341 - val_main_output_mse: 113747.3594 - val_aux_output_mse: 136506.3750\n",
      "Epoch 9/20\n",
      "146/146 [==============================] - 4s - loss: 0.0316 - main_output_loss: 0.0316 - aux_output_loss: 0.0882 - main_output_mse: 126502.9525 - aux_output_mse: 352890.7474 - val_loss: 0.0273 - val_main_output_loss: 0.0273 - val_aux_output_loss: 0.0338 - val_main_output_mse: 109368.3828 - val_aux_output_mse: 135287.1250\n",
      "Epoch 10/20\n",
      "146/146 [==============================] - 4s - loss: 0.0310 - main_output_loss: 0.0310 - aux_output_loss: 0.0884 - main_output_mse: 123884.5013 - aux_output_mse: 353496.1250 - val_loss: 0.0238 - val_main_output_loss: 0.0238 - val_aux_output_loss: 0.0337 - val_main_output_mse: 95263.3906 - val_aux_output_mse: 134938.3281\n",
      "Epoch 11/20\n",
      "146/146 [==============================] - 4s - loss: 0.0317 - main_output_loss: 0.0317 - aux_output_loss: 0.0837 - main_output_mse: 126941.9921 - aux_output_mse: 334971.0929 - val_loss: 0.0235 - val_main_output_loss: 0.0235 - val_aux_output_loss: 0.0335 - val_main_output_mse: 94167.9844 - val_aux_output_mse: 133805.7344\n",
      "Epoch 12/20\n",
      "146/146 [==============================] - 4s - loss: 0.0314 - main_output_loss: 0.0314 - aux_output_loss: 0.0819 - main_output_mse: 125792.5006 - aux_output_mse: 327639.4932 - val_loss: 0.0274 - val_main_output_loss: 0.0274 - val_aux_output_loss: 0.0334 - val_main_output_mse: 109568.1875 - val_aux_output_mse: 133699.3594\n",
      "Epoch 13/20\n",
      "146/146 [==============================] - 4s - loss: 0.0316 - main_output_loss: 0.0316 - aux_output_loss: 0.0798 - main_output_mse: 126280.3947 - aux_output_mse: 319390.9000 - val_loss: 0.0243 - val_main_output_loss: 0.0243 - val_aux_output_loss: 0.0335 - val_main_output_mse: 97306.3203 - val_aux_output_mse: 134033.2656\n",
      "Epoch 14/20\n",
      "146/146 [==============================] - 4s - loss: 0.0311 - main_output_loss: 0.0311 - aux_output_loss: 0.0860 - main_output_mse: 124510.3035 - aux_output_mse: 344049.1575 - val_loss: 0.0263 - val_main_output_loss: 0.0263 - val_aux_output_loss: 0.0337 - val_main_output_mse: 105343.9375 - val_aux_output_mse: 134683.3906\n",
      "Epoch 15/20\n",
      "146/146 [==============================] - 4s - loss: 0.0311 - main_output_loss: 0.0311 - aux_output_loss: 0.0900 - main_output_mse: 124499.5695 - aux_output_mse: 360140.2997 - val_loss: 0.0257 - val_main_output_loss: 0.0257 - val_aux_output_loss: 0.0338 - val_main_output_mse: 102943.6562 - val_aux_output_mse: 135112.9219\n",
      "Epoch 16/20\n",
      "146/146 [==============================] - 4s - loss: 0.0312 - main_output_loss: 0.0312 - aux_output_loss: 0.0967 - main_output_mse: 124789.5394 - aux_output_mse: 386895.5368 - val_loss: 0.0252 - val_main_output_loss: 0.0252 - val_aux_output_loss: 0.0338 - val_main_output_mse: 100984.7031 - val_aux_output_mse: 135297.2031\n",
      "Epoch 17/20\n",
      "146/146 [==============================] - 4s - loss: 0.0311 - main_output_loss: 0.0311 - aux_output_loss: 0.0981 - main_output_mse: 124464.6723 - aux_output_mse: 392469.5360 - val_loss: 0.0257 - val_main_output_loss: 0.0257 - val_aux_output_loss: 0.0338 - val_main_output_mse: 102854.7500 - val_aux_output_mse: 135326.2969\n",
      "Epoch 18/20\n",
      "146/146 [==============================] - 4s - loss: 0.0312 - main_output_loss: 0.0312 - aux_output_loss: 0.0728 - main_output_mse: 124620.7420 - aux_output_mse: 291165.4174 - val_loss: 0.0247 - val_main_output_loss: 0.0247 - val_aux_output_loss: 0.0338 - val_main_output_mse: 98857.2891 - val_aux_output_mse: 135324.7031\n",
      "Epoch 19/20\n",
      "146/146 [==============================] - 4s - loss: 0.0311 - main_output_loss: 0.0311 - aux_output_loss: 0.0825 - main_output_mse: 124566.1361 - aux_output_mse: 329883.8005 - val_loss: 0.0256 - val_main_output_loss: 0.0256 - val_aux_output_loss: 0.0338 - val_main_output_mse: 102513.5703 - val_aux_output_mse: 135319.1094\n",
      "Epoch 20/20\n",
      "146/146 [==============================] - 4s - loss: 0.0312 - main_output_loss: 0.0312 - aux_output_loss: 0.0810 - main_output_mse: 124924.9216 - aux_output_mse: 324164.3581 - val_loss: 0.0275 - val_main_output_loss: 0.0275 - val_aux_output_loss: 0.0338 - val_main_output_mse: 109959.0391 - val_aux_output_mse: 135314.3438\n"
     ]
    }
   ],
   "source": [
    "def train_model(train, test, epochs=20, verbose=1, batch_size=32):\n",
    "    input1_train, input2_train, output_train = train\n",
    "    input1_test, input2_test, output_test = test\n",
    "    with tf.device('/gpu:0'):\n",
    "        model = build_model()\n",
    "        history = keras.callbacks.History()\n",
    "        try:\n",
    "            model_results = model.fit(\n",
    "                {'main_input': input1_train, 'aux_input': input2_train},\n",
    "                {'main_output': output_train, 'aux_output': output_train},\n",
    "                epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
    "                validation_data=({'main_input': input1_test, 'aux_input': input2_test},\n",
    "                                 {'main_output': output_test, 'aux_output': output_test}),\n",
    "                callbacks=[history])\n",
    "        except KeyboardInterrupt:\n",
    "            model_results = None\n",
    "            pass\n",
    "    return model, model_results\n",
    "\n",
    "model, model_results = train_model((X1_train, X2_train, Y_train), (X1_test, X2_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test mse:', 109959.0390625)\n",
      "Predictions on training set: \n",
      "[ 379.]\n",
      "[  104.   114.   130.   131.   132.   140.   154.   164.   165.   182.\n",
      "   199.   203.   208.   217.   226.   228.   234.   237.   241.   247.\n",
      "   249.   253.   256.   259.   260.   261.   262.   263.   264.   269.\n",
      "   276.   278.   285.   288.   299.   304.   314.   324.   328.   332.\n",
      "   337.   341.   346.   347.   350.   352.   354.   357.   359.   362.\n",
      "   373.   377.   380.   389.   395.   399.   401.   406.   409.   415.\n",
      "   417.   418.   422.   426.   427.   429.   430.   431.   435.   445.\n",
      "   446.   447.   450.   453.   454.   457.   459.   461.   463.   466.\n",
      "   472.   476.   478.   482.   483.   487.   501.   504.   506.   509.\n",
      "   510.   513.   517.   518.   526.   527.   528.   535.   538.   547.\n",
      "   556.   560.   563.   569.   598.   605.   620.   623.   626.   646.\n",
      "   647.   650.   653.   666.   674.   688.   729.   733.   755.   763.\n",
      "   804.   810.   818.   821.   889.  1021.  1029.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67e304b550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp.reload(utils)\n",
    "# Evaluate model on validation set\n",
    "val_score = model.evaluate({'main_input': X1_test, 'aux_input': X2_test},\n",
    "                                           {'main_output': Y_test, 'aux_output': Y_test}, verbose=0)\n",
    "print('Test mse:', val_score[-2])\n",
    "utils.plot_history(model_results, filename=None)  # 'analysis/model_history.jpg')\n",
    "\n",
    "utils.plot_model(model, 'analysis/model.jpg')\n",
    "print('Predictions on training set: ')\n",
    "predicted = model.predict({'main_input': X1_train, 'aux_input': X2_train})\n",
    "print(np.unique(np.round(np.array(predicted)[0, :, 0] * MAX_SURVIVAL)))\n",
    "print(np.unique(np.round(np.array(predicted)[1, :, 0] * MAX_SURVIVAL)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 Conv(32[5x5x5], 64[3x3x3x]), 3 version (only tumor regions) -> Get's stuck at \"loss: 0.0798 - val_loss: 0.0534\"\n",
    "- Increase/Add dropout before and after the concatenation -> The same\n",
    "- Add conv layer (16, 32, 64) -> Get's stuck at \"loss: 0.6524 - val_loss: 0.6997\"\n",
    "- Use 7 versions (includes modalities) -> The same\n",
    "- Use Downsampling or Tumor2D -> Gets stuck at \"loss: 0.0798 - val_loss: 0.0534\"\n",
    "- Switch from Adam to Nadam optimizer -> The same (Nadam changes between first and second epoch)\n",
    "- Again Adam, Adding auxiliary output -> Epoch 1: \"loss: 0.4143 - val_loss: 0.3765\" -> at epoch 6 gets stuck at \"loss (both): 0.0798 val_loss(both): 0.0534\" (stop after 12 epochs)\n",
    "- Add manual Adam, Again use Tumor2D -> Epoch 1: \"loss: 0.3889 - val_loss: 0.3765\" -> gets stuck after second epoch (loss: 0.3661, val_loss as in epoch 1)\n",
    "- Switch back to 'Adam' -> Gets stuck at \"loss: 0.0798\"\n",
    "- Try out different hyperparameters for Adam doesn't improve the results\n",
    "- Nadam -> Again \"loss: 0.0798\"\n",
    "- Rmsprop -> Gets stuck after increasing loss at epoch 3: \"loss: 0.3661\n",
    "- Adadelta -> Gets stuck at \"loss: 0.6524\"\n",
    "- Stay at Adam, Increase/Decrease Dropout, Add Layers, Change order -> Best results still: \"loss: 0.0798\"\n",
    "- Upsampling: \"loss: 0.0798 - val_loss: 0.0534, main_output_mse: 319091.6469, val_main_output_mse: 213686.8281\" (stuck after second epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n",
      "[0.034528233110904694, 0.034528233110904694, 0.095063053071498871, 138112.9375, 380252.21875]\n",
      "Updated best model\n",
      "Test MSE in run 0: 138112.9375\n",
      "Unique predicted values: 458.0\n",
      "Train model...\n",
      "[0.019342562183737755, 0.019342562183737755, 0.25852763652801514, 77370.2578125, 1034110.4375]\n",
      "Updated best model\n",
      "Test MSE in run 1: 77370.2578125\n",
      "Unique predicted values: 417.0\n",
      "Train model...\n",
      "[0.043294474482536316, 0.043294474482536316, 0.31938618421554565, 173177.90625, 1277544.75]\n",
      "Test MSE in run 2: 173177.90625\n",
      "Unique predicted values: 440.0\n",
      "Train model...\n"
     ]
    }
   ],
   "source": [
    "# N-fold cross validation\n",
    "# 1.) http://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "# 2.) https://datascience.stackexchange.com/questions/11747/cross-validation-in-keras\n",
    "results = []\n",
    "best_model = None\n",
    "best_value = 150000\n",
    "def n_fold_cross_validation(folds=10):\n",
    "    global best_model, best_value\n",
    "    step = float(X.shape[0]) / folds\n",
    "    enc_table = np.eye(AGE_CLASSES)\n",
    "    ages_ohe = np.array([enc_table[int(round(x))] for x in df['Age']])\n",
    "    # Normalize labels\n",
    "    labels = df['Survival'] / MAX_SURVIVAL\n",
    "    for i in range(folds):\n",
    "        cuts = [int(step*i), int(step*(i+1))]\n",
    "        X1_train_front, X1_test, X1_train_back = np.split(X, cuts)\n",
    "        X2_train_front, X2_test, X2_train_back = np.split(ages_ohe, cuts)\n",
    "        Y_train_front, Y_test, Y_train_back = np.split(labels, cuts)\n",
    "        X1_train = np.concatenate([X1_train_front, X1_train_back])\n",
    "        X2_train = np.concatenate([X2_train_front, X2_train_back])\n",
    "        Y_train = np.concatenate([Y_train_front, Y_train_back])\n",
    "        print(\"Train model...\")\n",
    "        model, model_results = train_model((X1_train, X2_train, Y_train), (X1_test, X2_test, Y_test), epochs=20, verbose=0)\n",
    "        if model_results is None:\n",
    "            # Cause by KeyboardInterrupt\n",
    "            return results, None\n",
    "        val_score = model.evaluate({'main_input': X1_test, 'aux_input': X2_test},\n",
    "                                           {'main_output': Y_test, 'aux_output': Y_test}, verbose=0)\n",
    "        print(val_score)\n",
    "        test_mse = val_score[-2]\n",
    "        if test_mse < best_value:\n",
    "            best_value = test_mse\n",
    "            best_model = model\n",
    "            print(\"Updated best model\")\n",
    "        print(\"Test MSE in run {}: {}\".format(i, test_mse))\n",
    "        predicted = model.predict({'main_input': X1_train, 'aux_input': X2_train})\n",
    "        print(\"Unique predicted values: {}\".format(' '.join(\n",
    "            np.unique([str(x) for x in np.round(np.array(predicted)[0, :, 0] * MAX_SURVIVAL)]))))\n",
    "        results.append(test_mse)\n",
    "    return results, np.mean([x**2 for x in results])\n",
    "\n",
    "results2, cv_mse = n_fold_cross_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-664-a7023907b4e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'main_input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX1_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aux_input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX2_val\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mMAX_SURVIVAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mMAX_SURVIVAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# Check X vs labels?\n",
    "imp.reload(utils)\n",
    "predicted = model.predict({'main_input': X1_val, 'aux_input': X2_val})\n",
    "predicted = np.array(predicted)[0, :, 0]\n",
    "predicted *= MAX_SURVIVAL\n",
    "utils.plot_samples(X1_val, X2_val.argmax(axis=1), Y_val.values * MAX_SURVIVAL, predicted=predicted, samples=10, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: MSE: 124763.963416\n",
      "Age: 58, GT: 439.0, Prediction: 383.974432945\n",
      "Age: 56, GT: 368.0, Prediction: 384.191215038\n",
      "Age: 63, GT: 169.0, Prediction: 383.958101273\n",
      "Age: 52, GT: 359.0, Prediction: 384.108781815\n",
      "Age: 60, GT: 698.0, Prediction: 383.945643902\n",
      "Age: 66, GT: 495.0, Prediction: 383.993029594\n",
      "Age: 61, GT: 421.0, Prediction: 383.887529373\n",
      "Age: 48, GT: 515.0, Prediction: 384.235411882\n",
      "Age: 56, GT: 1155.0, Prediction: 384.250968695\n",
      "Age: 68, GT: 1278.0, Prediction: 384.145230055\n",
      "Age: 70, GT: 503.0, Prediction: 383.997350931\n",
      "Age: 67, GT: 269.0, Prediction: 384.050935507\n",
      "Age: 68, GT: 465.0, Prediction: 384.080737829\n",
      "Age: 39, GT: 788.0, Prediction: 383.932888508\n",
      "Age: 54, GT: 464.0, Prediction: 384.007513523\n",
      "Age: 52, GT: 616.0, Prediction: 384.15491581\n",
      "Age: 60, GT: 289.0, Prediction: 384.308725595\n",
      "test: MSE: 108178.730748\n"
     ]
    }
   ],
   "source": [
    "def mse(X1, X2, Y, verbose=False):\n",
    "    sum_ = 0\n",
    "    for i in range(len(X1)):\n",
    "        prediction = model.predict({'main_input': X1[i:i+1], 'aux_input': X2[i:i+1]})\n",
    "        prediction = prediction[0][0][0] * MAX_SURVIVAL  # Select main_output\n",
    "        gt = Y.values[i] * MAX_SURVIVAL\n",
    "        if verbose:\n",
    "            print('Age: {}, GT: {}, Prediction: {}'.format(\n",
    "                X2[i].argmax(),\n",
    "                gt,\n",
    "                prediction))\n",
    "        sum_ += float(gt - prediction)**2\n",
    "    return 'MSE: {}'.format(sum_ / len(X1))\n",
    "\n",
    "print('train: {}'.format(mse(X1_train, X2_train, Y_train)))\n",
    "print('test: {}'.format(mse(X1_test, X2_test, Y_test, verbose=True)))\n",
    "# print('val: {}'.format(mse(X1_val, X2_val, Y_val, verbose=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 163 patients with tumor images of sizes 240x240 of which we have 155"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start\n",
    "Implementing a concatenated model as shown in the Docs: https://keras.io/getting-started/functional-api-guide/#multi-input-and-multi-output-models\n",
    "The model uses a small common CNN for processing one patient (155 slices x 128 width x 128 height) and just inserts the age at a certain point. With this simple model we get really bad results (main_output_loss: 263381.5156 [not getting better]).\n",
    "\n",
    "\n",
    "### Possible improvements\n",
    "1. ~~Conv3D (in CNN) which gets a 4D input - therefore add the tumor region as a dimension (transform input image into three images containing each tumor region seperately~~)\n",
    "2. ~~One-hot encoder (in sklearn or implement manually)\n",
    "  [ I tried Keras Lambda layer but after fixing the shapes keras told me that I'm not allowed to concatenate with a non input layer ]~~\n",
    "3. ~~Add modalities, rescale images (8GB -> 2GB)~~\n",
    "4. Group survival rate into few classes changing the regression task into a classification task (with softmax).\n",
    "5. Evaluate if LSTM is useful for this task (before concatenating the two branches or as a concatenator?)\n",
    "6. ~~Evaluate our optimizer (RMSprp vs Adam vs AdaDelta)\n",
    "    -> RMSprop doesn't learn at all (Adam does!)\n",
    "    -> First run was without normalization but no improvement (After normalization quite good results)~~\n",
    "7. I red full batch learning is the best way for training on few training data - check if this is helpful.\n",
    "8. Use for a patient nx, ny and nz at the same time\n",
    "9. Data augmentation?\n",
    "10. ~~Check if the dimension are correctly set for the conv3d layers - i got the feeling, that the first dimension are the modalities/results instead of the slices.~~\n",
    "\n",
    "##### Optimizer:\n",
    "RMSprop uses:\n",
    "    - Momentum taking knowledge from previous steps into account about where we should be heading\n",
    "        (prevents gradient descent to oscillate)\n",
    "    - Uses recent gradients to adjust alpha (when the gradient is very large, alpha is reduced and vice-versa)\n",
    "    - Later we should test if AdaDelta or Adam are improving our results (quite similar to RMSprop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
